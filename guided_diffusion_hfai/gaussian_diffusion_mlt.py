"""
This code started out as a PyTorch port of Ho et al's diffusion models:
https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py

Docstrings have been added, as well as DDIM sampling and a new collection of beta schedules.
"""
import copy

# import torch

from guided_diffusion_hfai.gaussian_diffusion import *
from guided_diffusion_hfai.respace import *
import random
import torch
import torch.nn as nn
import torch.nn.functional


class GaussianDiffusionMLT(SpacedDiffusion):
    """
    NO consider about batchsize
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        new_mean = (
            p_mean_var["mean"].float() - gradient_gen.float() + new_gradient_gen.float() + new_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, new_gradient_gen, new_gradient_cls
        return new_mean

    def project_conflict(self, grad1, grad2, shape):
        new_grad1 = torch.flatten(grad1)
        new_grad2 = torch.flatten(grad2)

        g_1_g_2 = torch.dot(new_grad1, new_grad2)

        if g_1_g_2 < 0: # later could change to partial conflict
            new_grad1 -= ((g_1_g_2) * new_grad2/ (new_grad2.norm() ** 2))
        new_grad1 = new_grad1.view(shape)
        return new_grad1

    def condition_mean(self, cond_fn, *args, **kwargs):
        return self.condition_mean_mtl(self._wrap_model(cond_fn), *args, **kwargs)


class GaussianDiffusionMLT2(SpacedDiffusion):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT2, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        new_mean = (
            p_mean_var["mean"].float() - gradient_gen.float() + new_gradient_gen.float() + new_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, new_gradient_gen, new_gradient_cls
        return new_mean

    def project_conflict(self, grad1, grad2, shape):
        new_grad1 = torch.flatten(grad1, start_dim=1)
        new_grad2 = torch.flatten(grad2, start_dim=1)

        # g1 * g2 --------------- (batchsize,)
        g_1_g_2 = torch.sum(new_grad1 * new_grad2, dim=1)
        g_1_g_2 = torch.clamp(g_1_g_2, max=0.0)

        # ||g2||^2 ----------------- (batchsize,)
        norm_g2 = new_grad2.norm(dim=1) **2
        if torch.any(norm_g2 == 0.0):
            return new_grad1.view(shape)

        # (g1 * g2)/||g2||^2 ------------------- (batchsize,)
        g12_o_normg2 = g_1_g_2/norm_g2
        g12_o_normg2 = torch.unsqueeze(g12_o_normg2, dim=1)
        # why zero has problem?
        # g1
        new_grad1 -= ((g12_o_normg2) * new_grad2)
        new_grad1 = new_grad1.view(shape)
        return new_grad1

    def condition_mean(self, cond_fn, *args, **kwargs):
        return self.condition_mean_mtl(self._wrap_model(cond_fn), *args, **kwargs)

class GaussianDiffusionMLT_DiversityGrad(GaussianDiffusionMLT):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT_DiversityGrad, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                                 model_mean_type=model_mean_type,
                                                                 model_var_type=model_var_type,
                                                                 loss_type=loss_type,
                                                                 rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )

        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        gradient_gen = torch.zeros_like(out["mean"])
        gradient_cls = torch.zeros_like(out["mean"])
        if cond_fn is not None:
            out["mean"], gradient_gen, gradient_cls = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )

        gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        (gradient_gen, gradient_cls, gradient_diversity) = self.project_conflict(gradient_gen, gradient_cls,
                                                                                 gradient_diversity, gradient_gen.shape)

        out["mean"] = (_extract_into_tensor(self.posterior_mean_coef2, t, x.shape) * x + gradient_gen).float() + \
                      gradient_cls.float()
        sample = out["mean"] + gradient_diversity.float()
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        new_mean = p_mean_var["mean"]
        return new_mean, gradient_gen, gradient_cls

    def project_conflict(self, grad1, grad2, grad3, shape):
        grad1 = torch.flatten(grad1)
        grad2 = torch.flatten(grad2)
        grad3 = torch.flatten(grad3)
        grads = [grad1, grad2, grad3]
        pc_grad, num_grads = copy.deepcopy(grads), 3
        for g_i in pc_grad:
            random.shuffle(grads)
            for g_j in grads:
                g_i_g_j = torch.dot(g_i, g_j)
                if g_i_g_j < 0:
                    g_i -= (g_i_g_j) * g_j / (g_j.norm() ** 2)
        for i in range(num_grads):
            pc_grad[i] = pc_grad[i].view(shape)
        return pc_grad


class GaussianDiffusionMLT_Analyse(GaussianDiffusionMLT):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """
    timestep_coss_dc = []  # diffusion classification
    timestep_mags_dc = []  # diff - class

    timestep_coss_ddv = []  # diff - div
    timestep_mags_ddv = []  # diff - dv

    timestep_coss_cdv = []  # class = div
    timestep_mags_cdv = []  # class - div


    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):

        super(GaussianDiffusionMLT_Analyse, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                                 model_mean_type=model_mean_type,
                                                                 model_var_type=model_var_type,
                                                                 loss_type=loss_type,
                                                                 rescale_timesteps=rescale_timesteps)


    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        gradient_cls = torch.zeros_like(x)
        if cond_fn is not None:
            out["mean"], gradient_cls = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
        gradient_div = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise

        sample = out["mean"] + gradient_div

        coss_dc = self.direction_conflict(gradient_gen.clone(), gradient_cls.clone())
        self.timestep_coss_dc.append(coss_dc)
        self.timestep_mags_dc.append(self.magnitude_conflict(gradient_gen.clone(), gradient_cls.clone()))

        coss_ddiv = self.direction_conflict(gradient_gen.clone(), gradient_div.clone())
        self.timestep_coss_ddv.append(coss_ddiv)
        self.timestep_mags_ddv.append(self.magnitude_conflict(gradient_gen.clone(), gradient_div.clone()))

        coss_cdv = self.direction_conflict(gradient_cls.clone(), gradient_div.clone())
        self.timestep_coss_cdv.append(coss_cdv)
        self.timestep_mags_cdv.append(self.magnitude_conflict(gradient_cls.clone(), gradient_div.clone()))

        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        new_mean = (
                p_mean_var["mean"].float() + p_mean_var["variance"] * gradient.float()
        )
        return new_mean, p_mean_var["variance"] * gradient.float()

    def direction_conflict(self, grad1, grad2):
        grad1_norm = nn.functional.normalize(torch.flatten(grad1, start_dim=1), dim=1)
        grad2_norm = nn.functional.normalize(torch.flatten(grad2, start_dim=1), dim=1)
        return (grad1_norm * grad2_norm).sum(dim=1)
        pass

    def magnitude_conflict(self, grad1, grad2):
        fgrad1 = torch.flatten(grad1, start_dim=1)
        fgrad2 = torch.flatten(grad2, start_dim=1)
        fgrad1_norm = fgrad1.norm(dim=1)
        fgrad2_norm = fgrad2.norm(dim=1)
        magnitude = (2 * fgrad1_norm * fgrad2_norm)/(fgrad1_norm**2 + fgrad2_norm**2)
        return magnitude
        pass


class GaussianDiffusionMLTCDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTCDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        if cond_fn is not None:
            out["mean"], gradient_div = self.condition_mean(
                cond_fn, out, x, t, nonzero_mask, model_kwargs=model_kwargs
            )
        else:
            noise = th.randn_like(x)
            gradient_div = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        sample = out["mean"] + gradient_div
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        #diffusion - classification conflict
        new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        # classification - diversity conflict
        final_gradient_cls = self.project_conflict(new_gradient_cls.clone(), gradient_div.clone(), g_cls_shape)
        final_gradient_div = self.project_conflict(gradient_div.clone(), new_gradient_cls.clone(), g_cls_shape)

        new_mean = (
            p_mean_var["mean"].float() - gradient_gen.float() + new_gradient_gen.float() + final_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, new_gradient_gen, new_gradient_cls, final_gradient_cls
        return new_mean, final_gradient_div


class GaussianDiffusionMLTCDiv2(GaussianDiffusionMLT2):
    """
    Similar to CDiv but avoid contact between diffusion - diversity pair

    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTCDiv2, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        if cond_fn is not None:
            out["mean"], gradient_div = self.condition_mean(
                cond_fn, out, x, t, nonzero_mask, model_kwargs=model_kwargs
            )
        else:
            noise = th.randn_like(x)
            gradient_div = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        sample = out["mean"] + gradient_div
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        #diffusion - classification conflict
        new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        # classification - diversity conflict
        final_gradient_cls = self.project_conflict(new_gradient_cls.clone(), gradient_div.clone(), g_cls_shape)
        final_gradient_div = self.project_conflict(gradient_div.clone(), gradient_cls.clone(), g_cls_shape) # gradient_cls not new_gradient_cls to avoid interaction between gradient_div and gradient_gen
        new_mean = (
            p_mean_var["mean"].float() - gradient_gen.float() + new_gradient_gen.float() + final_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, new_gradient_gen, new_gradient_cls, final_gradient_cls
        return new_mean, final_gradient_div

class GaussianDiffusionMLTChannelConflict(GaussianDiffusionMLT2):
    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTChannelConflict, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                                    model_mean_type=model_mean_type,
                                                                    model_var_type=model_var_type,
                                                                    loss_type=loss_type,
                                                                    rescale_timesteps=rescale_timesteps)

    def project_conflict(self, grad1, grad2, shape):
        """project conflict considering channel conflicts"""
        new_grad1 = torch.flatten(grad1, start_dim=2)
        new_grad2 = torch.flatten(grad2, start_dim=2)

        # g1 * g2 --------------- (batchsize, channels)
        g_1_g_2 = torch.sum(new_grad1 * new_grad2, dim=2)
        g_1_g_2 = torch.clamp(g_1_g_2, max=0.0)

        # ||g2||^2 ----------------- (batchsize, channels)
        norm_g2 = new_grad2.norm(dim=2) ** 2
        if torch.any(norm_g2 == 0.0):
            return new_grad1.view(shape)

        # (g1 * g2)/||g2||^2 ------------------- (batchsize, channels)
        g12_o_normg2 = g_1_g_2 / norm_g2
        g12_o_normg2 = torch.unsqueeze(g12_o_normg2, dim=2)
        # why zero has problem?
        # g1
        new_grad1 -= ((g12_o_normg2) * new_grad2)
        new_grad1 = new_grad1.view(shape)
        return new_grad1


class GaussianDiffusionMLTDDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_diversity.clone(), gradient_gen.shape)
            new_gradient_diversity = self.project_conflict(gradient_diversity.clone(), gradient_gen.clone(), gradient_gen.shape)
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

class GaussianDiffusionMLTDDiv_stepcontrol(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv_stepcontrol, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)


    def p_sample_loop(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        specified_t=250
    ):
        """
        Generate samples from the model.

        :param model: the model module.
        :param shape: the shape of the samples, (N, C, H, W).
        :param noise: if specified, the noise from the encoder to sample.
                      Should be of the same shape as `shape`.
        :param clip_denoised: if True, clip x_start predictions to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :param device: if specified, the device to create the samples on.
                       If not specified, use a model parameter's device.
        :param progress: if True, show a tqdm progress bar.
        :return: a non-differentiable batch of samples.
        """
        final = None
        for sample in self.p_sample_loop_progressive(
            model,
            shape,
            noise=noise,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            cond_fn=cond_fn,
            model_kwargs=model_kwargs,
            device=device,
            progress=progress,
            specified_t=specified_t
        ):
            final = sample
        return final["sample"]

    def p_sample_loop_progressive(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        specified_t=250
    ):
        """
        Generate samples from the model and yield intermediate samples from
        each timestep of diffusion.

        Arguments are the same as p_sample_loop().
        Returns a generator over dicts, where each dict is the return value of
        p_sample().
        """
        if device is None:
            device = next(model.parameters()).device
        assert isinstance(shape, (tuple, list))
        if noise is not None:
            img = noise
        else:
            img = th.randn(*shape, device=device)
        indices = list(range(self.num_timesteps))[::-1]

        if progress:
            # Lazy import so that we don't depend on tqdm.
            from tqdm.auto import tqdm

            indices = tqdm(indices)

        for i in indices:
            t = th.tensor([i] * shape[0], device=device)
            with th.no_grad():
                out = self.p_sample(
                    model,
                    img,
                    t,
                    clip_denoised=clip_denoised,
                    denoised_fn=denoised_fn,
                    cond_fn=cond_fn,
                    model_kwargs=model_kwargs,
                    specified_t=specified_t
                )
                yield out
                img = out["sample"]

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        specified_t = 250
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            # print(t)
            if t[0] > specified_t:
                new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_diversity.clone(), gradient_gen.shape)
                new_gradient_diversity = self.project_conflict(gradient_diversity.clone(), gradient_gen.clone(), gradient_gen.shape)
            else:
                new_gradient_gen = gradient_gen
                new_gradient_diversity = gradient_diversity
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}


class GaussianDiffusionMLTDDiv1wayDiff(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv1wayDiff, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_diversity.clone(), gradient_gen.shape)
            new_gradient_diversity = gradient_diversity
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}


class GaussianDiffusionMLTDDiv1wayDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv1wayDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = gradient_gen
            new_gradient_diversity = self.project_conflict(gradient_diversity.clone(), gradient_gen.clone(), gradient_gen.shape)
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}


class GaussianDiffusionMLT1wayDiffScaleDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wayDiffScaleDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)


    def p_sample_loop(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        scale_div=1.0
    ):
        """
        Generate samples from the model.

        :param model: the model module.
        :param shape: the shape of the samples, (N, C, H, W).
        :param noise: if specified, the noise from the encoder to sample.
                      Should be of the same shape as `shape`.
        :param clip_denoised: if True, clip x_start predictions to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :param device: if specified, the device to create the samples on.
                       If not specified, use a model parameter's device.
        :param progress: if True, show a tqdm progress bar.
        :return: a non-differentiable batch of samples.
        """
        final = None
        for sample in self.p_sample_loop_progressive(
            model,
            shape,
            noise=noise,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            cond_fn=cond_fn,
            model_kwargs=model_kwargs,
            device=device,
            progress=progress,
            scale_div=scale_div
        ):
            final = sample
        return final["sample"]

    def p_sample_loop_progressive(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        scale_div=1.0
    ):
        """
        Generate samples from the model and yield intermediate samples from
        each timestep of diffusion.

        Arguments are the same as p_sample_loop().
        Returns a generator over dicts, where each dict is the return value of
        p_sample().
        """
        if device is None:
            device = next(model.parameters()).device
        assert isinstance(shape, (tuple, list))
        if noise is not None:
            img = noise
        else:
            img = th.randn(*shape, device=device)
        indices = list(range(self.num_timesteps))[::-1]

        if progress:
            # Lazy import so that we don't depend on tqdm.
            from tqdm.auto import tqdm

            indices = tqdm(indices)

        for i in indices:
            t = th.tensor([i] * shape[0], device=device)
            with th.no_grad():
                out = self.p_sample(
                    model,
                    img,
                    t,
                    clip_denoised=clip_denoised,
                    denoised_fn=denoised_fn,
                    cond_fn=cond_fn,
                    model_kwargs=model_kwargs,
                    scale_div=scale_div
                )
                yield out
                img = out["sample"]

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        scale_div=1.0
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_diversity.clone() * scale_div, gradient_gen.shape)
            new_gradient_diversity = gradient_diversity
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}


class GaussianDiffusionMLT1wayDivScaleDiff(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wayDivScaleDiff, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)


    def p_sample_loop(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        scale_diff=1.0
    ):
        """
        Generate samples from the model.

        :param model: the model module.
        :param shape: the shape of the samples, (N, C, H, W).
        :param noise: if specified, the noise from the encoder to sample.
                      Should be of the same shape as `shape`.
        :param clip_denoised: if True, clip x_start predictions to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :param device: if specified, the device to create the samples on.
                       If not specified, use a model parameter's device.
        :param progress: if True, show a tqdm progress bar.
        :return: a non-differentiable batch of samples.
        """
        final = None
        for sample in self.p_sample_loop_progressive(
            model,
            shape,
            noise=noise,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            cond_fn=cond_fn,
            model_kwargs=model_kwargs,
            device=device,
            progress=progress,
            scale_diff=scale_diff
        ):
            final = sample
        return final["sample"]

    def p_sample_loop_progressive(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
        scale_diff=1.0
    ):
        """
        Generate samples from the model and yield intermediate samples from
        each timestep of diffusion.

        Arguments are the same as p_sample_loop().
        Returns a generator over dicts, where each dict is the return value of
        p_sample().
        """
        if device is None:
            device = next(model.parameters()).device
        assert isinstance(shape, (tuple, list))
        if noise is not None:
            img = noise
        else:
            img = th.randn(*shape, device=device)
        indices = list(range(self.num_timesteps))[::-1]

        if progress:
            # Lazy import so that we don't depend on tqdm.
            from tqdm.auto import tqdm

            indices = tqdm(indices)

        for i in indices:
            t = th.tensor([i] * shape[0], device=device)
            with th.no_grad():
                out = self.p_sample(
                    model,
                    img,
                    t,
                    clip_denoised=clip_denoised,
                    denoised_fn=denoised_fn,
                    cond_fn=cond_fn,
                    model_kwargs=model_kwargs,
                    scale_diff=scale_diff
                )
                yield out
                img = out["sample"]

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        scale_diff=1.0
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = gradient_gen.clone()
            new_gradient_diversity = self.project_conflict(gradient_diversity.clone(), gradient_gen.clone() * scale_diff, gradient_gen.shape)
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}


class GaussianDiffusionMLTDDiv_Adaptive(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv_Adaptive, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_diversity.clone(), gradient_gen.shape)
            new_gradient_diversity = self.project_conflict(gradient_diversity.clone(), gradient_gen.clone(), gradient_gen.shape)
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def project_conflict(self, grad1, grad2, shape):
        new_grad1 = torch.flatten(grad1, start_dim=1)
        new_grad2 = torch.flatten(grad2, start_dim=1)

        # g1 * g2 --------------- (batchsize,)
        g_1_g_2 = torch.sum(new_grad1 * new_grad2, dim=1)
        g_1_g_2 = torch.clamp(g_1_g_2, max=0.0)

        # ||g2||^2 ----------------- (batchsize,)
        norm_g2 = new_grad2.norm(dim=1) **2
        if torch.any(norm_g2 == 0.0):
            return new_grad1.view(shape)

        # (g1 * g2)/||g2||^2 ------------------- (batchsize,)
        g12_o_normg2 = g_1_g_2/norm_g2
        g12_o_normg2 = torch.unsqueeze(g12_o_normg2, dim=1)
        # why zero has problem?

        magnitude_cf = torch.unsqueeze(self.magnitude_conflict(grad1, grad2), dim=1)
        # g1
        new_grad1 -= ((g12_o_normg2 * (1 - magnitude_cf)) * new_grad2)
        new_grad1 = new_grad1.view(shape)
        return new_grad1

    def magnitude_conflict(self, grad1, grad2):
        fgrad1 = torch.flatten(grad1, start_dim=1)
        fgrad2 = torch.flatten(grad2, start_dim=1)
        fgrad1_norm = fgrad1.norm(dim=1)
        fgrad2_norm = fgrad2.norm(dim=1)
        magnitude = (2 * fgrad1_norm * fgrad2_norm)/(fgrad1_norm**2 + fgrad2_norm**2)
        return magnitude
        pass


class GaussianDiffusionMLTDDiv_ExcSch(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTDDiv_ExcSch, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            # gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']

            # confirm convert eps work

            # get eps here
            eps = self._predict_eps_from_xstart(x_t=x, t=t, pred_xstart=out['pred_xstart'])
            # temp_pred_xstart = self._predict_xstart_from_eps(x_t=x, t = t, eps=eps)
            #
            # print(temp_pred_xstart - out['pred_xstart'])
            # get noise here
            diversity = noise

            new_eps = self.project_conflict(eps.clone(), diversity.clone(), diversity.shape)
            new_diversity = self.project_conflict(diversity.clone(), eps.clone(), diversity.shape)

            # convert eps to pred_xstart
            out["pred_xstart"] = self._predict_xstart_from_eps(x_t=x, t=t, eps=new_eps)
            new_gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            # convert noise to diversity gradient
            new_gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * new_diversity


            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, diversity, new_eps
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def _predict_xstart_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * eps
        )

    def _predict_xstart_from_xprev(self, x_t, t, xprev):
        assert x_t.shape == xprev.shape
        return (  # (xprev - coef2*x_t) / coef1
            _extract_into_tensor(1.0 / self.posterior_mean_coef1, t, x_t.shape) * xprev
            - _extract_into_tensor(
                self.posterior_mean_coef2 / self.posterior_mean_coef1, t, x_t.shape
            )
            * x_t
        )

    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - pred_xstart
        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)


class GaussianDiffusionMLT1wayDiffExcSch(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wayDiffExcSch, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            # gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']

            # confirm convert eps work

            # get eps here
            eps = self._predict_eps_from_xstart(x_t=x, t=t, pred_xstart=out['pred_xstart'])

            # get noise here
            diversity = noise

            new_eps = self.project_conflict(eps.clone(), diversity.clone(), diversity.shape)
            new_diversity = diversity.clone()


            # convert eps to pred_xstart
            out["pred_xstart"] = self._predict_xstart_from_eps(x_t=x, t=t, eps=new_eps)
            new_gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            # convert noise to diversity gradient
            new_gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * new_diversity


            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, diversity, new_eps
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def _predict_xstart_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * eps
        )

    def _predict_xstart_from_xprev(self, x_t, t, xprev):
        assert x_t.shape == xprev.shape
        return (  # (xprev - coef2*x_t) / coef1
            _extract_into_tensor(1.0 / self.posterior_mean_coef1, t, x_t.shape) * xprev
            - _extract_into_tensor(
                self.posterior_mean_coef2 / self.posterior_mean_coef1, t, x_t.shape
            )
            * x_t
        )

    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - pred_xstart
        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)


class GaussianDiffusionMLT1wayDiffExcSchAdaptiveM(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wayDiffExcSchAdaptiveM, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:
            # gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']

            # confirm convert eps work

            # get eps here
            eps = self._predict_eps_from_xstart(x_t=x, t=t, pred_xstart=out['pred_xstart'])

            # get noise here
            diversity = noise

            new_eps = self.project_conflict(eps.clone(), diversity.clone(), diversity.shape)
            new_diversity = diversity.clone()


            # convert eps to pred_xstart
            out["pred_xstart"] = self._predict_xstart_from_eps(x_t=x, t=t, eps=new_eps)
            new_gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            # convert noise to diversity gradient
            new_gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * new_diversity


            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, diversity, new_eps
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def project_conflict(self, grad1, grad2, shape):
        new_grad1 = torch.flatten(grad1, start_dim=1)
        new_grad2 = torch.flatten(grad2, start_dim=1)

        # g1 * g2 --------------- (batchsize,)
        g_1_g_2 = torch.sum(new_grad1 * new_grad2, dim=1)
        g_1_g_2 = torch.clamp(g_1_g_2, max=0.0)

        # ||g2||^2 ----------------- (batchsize,)
        norm_g2 = new_grad2.norm(dim=1) **2
        if torch.any(norm_g2 == 0.0):
            return new_grad1.view(shape)

        # (g1 * g2)/||g2||^2 ------------------- (batchsize,)
        g12_o_normg2 = g_1_g_2/norm_g2
        g12_o_normg2 = torch.unsqueeze(g12_o_normg2, dim=1)
        # why zero has problem?

        magnitude_cf = torch.unsqueeze(self.magnitude_conflict(grad1, grad2), dim=1)
        # g1
        new_grad1 -= ((g12_o_normg2 * (1 - magnitude_cf)) * new_grad2)
        new_grad1 = new_grad1.view(shape)
        return new_grad1

    def magnitude_conflict(self, grad1, grad2):
        fgrad1 = torch.flatten(grad1, start_dim=1)
        fgrad2 = torch.flatten(grad2, start_dim=1)
        fgrad1_norm = fgrad1.norm(dim=1)
        fgrad2_norm = fgrad2.norm(dim=1)
        magnitude = (2 * fgrad1_norm * fgrad2_norm)/(fgrad1_norm**2 + fgrad2_norm**2)
        return magnitude

    def _predict_xstart_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * eps
        )

    def _predict_xstart_from_xprev(self, x_t, t, xprev):
        assert x_t.shape == xprev.shape
        return (  # (xprev - coef2*x_t) / coef1
            _extract_into_tensor(1.0 / self.posterior_mean_coef1, t, x_t.shape) * xprev
            - _extract_into_tensor(
                self.posterior_mean_coef2 / self.posterior_mean_coef1, t, x_t.shape
            )
            * x_t
        )

    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):
        return (
            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t
            - pred_xstart
        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)


class GaussianDiffusionMLTCDiffDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTCDiffDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        if cond_fn is not None:
            out["mean"], gradient_comb = self.condition_mean(
                cond_fn, out, x, t, nonzero_mask, model_kwargs=model_kwargs
            )
        else:
            noise = th.randn_like(x)
            gradient_comb = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        sample = out["mean"] + gradient_comb
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        #diffusion - diversity combination
        comb_gradient_gen = gradient_gen + gradient_div

        #comb - classification conflict
        new_gradient_cls = self.project_conflict(gradient_cls.clone(), comb_gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        new_gradient_gen = self.project_conflict(comb_gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        new_mean = (
            p_mean_var["mean"].float() - gradient_gen.float() + new_gradient_cls
        )
        del gradient_cls, gradient_gen, new_gradient_cls
        return new_mean, new_gradient_gen


class GaussianDiffusionMLT1wcCDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wcCDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        if cond_fn is not None:
            out["mean"], gradient_div = self.condition_mean(
                cond_fn, out, x, t, nonzero_mask, model_kwargs=model_kwargs
            )
        else:
            noise = th.randn_like(x)
            gradient_div = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        sample = out["mean"] + gradient_div
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        # #diffusion - classification conflict
        # new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        # new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        # classification - diversity conflict
        final_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_div.clone(), g_cls_shape)
        final_gradient_div = gradient_div

        new_mean = (
            p_mean_var["mean"].float() + final_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, final_gradient_cls
        return new_mean, final_gradient_div


class GaussianDiffusionMLT1wdCDiv(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLT1wdCDiv, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t

        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0

        if cond_fn is not None:
            out["mean"], gradient_div = self.condition_mean(
                cond_fn, out, x, t, nonzero_mask, model_kwargs=model_kwargs
            )
        else:
            noise = th.randn_like(x)
            gradient_div = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        sample = out["mean"] + gradient_div
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        # #diffusion - classification conflict
        # new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        # new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        # classification - diversity conflict
        final_gradient_cls = gradient_cls
        final_gradient_div = self.project_conflict(gradient_div.clone(), gradient_cls.clone(), g_cls_shape)

        new_mean = (
            p_mean_var["mean"].float() + final_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, final_gradient_cls
        return new_mean, final_gradient_div


class GaussianDiffusionMLTCDivOnly(GaussianDiffusionMLTCDiv):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionMLTCDivOnly, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                   model_mean_type=model_mean_type,
                                                   model_var_type=model_var_type,
                                                   loss_type=loss_type,
                                                   rescale_timesteps=rescale_timesteps)


    def condition_mean_mtl(self, cond_fn, p_mean_var, x, t, nonzero_mask, model_kwargs=None):
        """
        Compute the mean for the previous step, given a function cond_fn that
        computes the gradient of a conditional log probability with respect to
        x. In particular, cond_fn computes grad(log(p(y|x))), and we want to
        condition on y.

        This uses the conditioning strategy from Sohl-Dickstein et al. (2015).
        """
        gradient = cond_fn(x, self._scale_timesteps(t), **model_kwargs)
        gradient_cls = p_mean_var["variance"] * gradient.float()
        gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * p_mean_var['pred_xstart']

        noise = th.randn_like(x)
        gradient_div = nonzero_mask * th.exp(0.5 * p_mean_var["log_variance"]) * noise

        g_cls_shape = gradient_cls.shape
        g_gen_shape = gradient_gen.shape
        assert g_cls_shape == g_gen_shape

        #diffusion - classification conflict
        # new_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_gen.clone(), g_cls_shape) # check if gradient_cls change / changed -> using clone -> does not change
        # new_gradient_gen = self.project_conflict(gradient_gen.clone(), gradient_cls.clone(), g_gen_shape) # check if gradient_gen change / changed -> using clone -> does not change

        # classification - diversity conflict
        final_gradient_cls = self.project_conflict(gradient_cls.clone(), gradient_div.clone(), g_cls_shape)
        final_gradient_div = self.project_conflict(gradient_div.clone(), gradient_cls.clone(), g_cls_shape)

        new_mean = (
            p_mean_var["mean"].float() + final_gradient_cls.float()
        )
        del gradient_cls, gradient_gen, final_gradient_cls
        return new_mean, final_gradient_div

class GaussianDiffusionGradNorm(GaussianDiffusionMLT2):
    """
    Utilities for training and sampling diffusion models.

    Ported directly from here, and then adapted over time to further experimentation.
    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42

    :param betas: a 1-D numpy array of betas for each diffusion timestep,
                  starting at T and going to 1.
    :param model_mean_type: a ModelMeanType determining what the model outputs.
    :param model_var_type: a ModelVarType determining how variance is output.
    :param loss_type: a LossType determining the loss function to use.
    :param rescale_timesteps: if True, pass floating point timesteps into the
                              model so that they are always scaled like in the
                              original paper (0 to 1000).
    """

    def __int__(self,
        use_timesteps,
        *,
        betas,
        model_mean_type,
        model_var_type,
        loss_type,
        rescale_timesteps=False,
    ):
        super(GaussianDiffusionGradNorm, self).__init__(use_timesteps=use_timesteps, betas=betas,
                                                           model_mean_type=model_mean_type,
                                                           model_var_type=model_var_type,
                                                           loss_type=loss_type,
                                                           rescale_timesteps=rescale_timesteps)
        self.original_grad_div_mag = None
        self.original_grad_gen_mag = None

    def p_sample(
        self,
        model,
        x,
        t,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
    ):
        """
        Batch consider

        Sample x_{t-1} from the model at the given timestep.

        :param model: the model to sample from.
        :param x: the current tensor at x_{t-1}.
        :param t: the value of t, starting at 0 for the first diffusion step.
        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :return: a dict containing the following keys:
                 - 'sample': a random sample from the model.
                 - 'pred_xstart': a prediction of x_0.
        """
        out = self.p_mean_variance(
            model,
            x,
            t,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            model_kwargs=model_kwargs,
        )
        self.t = t
        noise = th.randn_like(x)
        nonzero_mask = (
            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))
        )  # no noise when t == 0
        if cond_fn is not None:
            out["mean"] = self.condition_mean(
                cond_fn, out, x, t, model_kwargs=model_kwargs
            )
        else:

            gradient_diversity = nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
            gradient_gen = _extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * out['pred_xstart']
            if self.original_grad_gen_mag is None:
                self.original_grad_gen_mag = gradient_gen.clone()
                self.original_grad_gen_mag = self.get_norm(self.original_grad_gen_mag)
            if self.original_grad_div_mag is None:
                self.original_grad_div_mag = gradient_diversity.clone()
                self.original_grad_div_mag = self.get_norm(self.original_grad_div_mag)
            new_gradient_gen, new_gradient_diversity = self.grad_norm(gradient_gen.clone(), gradient_diversity.clone())
            sample = out["mean"] - gradient_gen + new_gradient_gen + new_gradient_diversity
            del gradient_gen, new_gradient_gen, new_gradient_diversity, gradient_diversity
            return {"sample": sample, "pred_xstart": out["pred_xstart"]}

        sample = out["mean"] + nonzero_mask * th.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}

    def get_norm(self, gradient_matrix):
        gradient_vector = torch.flatten(gradient_matrix, start_dim=1)
        norm_gradient = gradient_vector.norm(dim=1)
        return norm_gradient

    def get_norm_flatten(self, gradient_matrix):
        gradient_vector = torch.flatten(gradient_matrix, start_dim=1)
        norm_gradient = gradient_vector.norm(dim=1)
        return norm_gradient, gradient_vector

    def p_sample_loop(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
    ):
        """
        Generate samples from the model.

        :param model: the model module.
        :param shape: the shape of the samples, (N, C, H, W).
        :param noise: if specified, the noise from the encoder to sample.
                      Should be of the same shape as `shape`.
        :param clip_denoised: if True, clip x_start predictions to [-1, 1].
        :param denoised_fn: if not None, a function which applies to the
            x_start prediction before it is used to sample.
        :param cond_fn: if not None, this is a gradient function that acts
                        similarly to the model.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.
        :param device: if specified, the device to create the samples on.
                       If not specified, use a model parameter's device.
        :param progress: if True, show a tqdm progress bar.
        :return: a non-differentiable batch of samples.
        """
        final = None
        for sample in self.p_sample_loop_progressive(
            model,
            shape,
            noise=noise,
            clip_denoised=clip_denoised,
            denoised_fn=denoised_fn,
            cond_fn=cond_fn,
            model_kwargs=model_kwargs,
            device=device,
            progress=progress,
        ):
            final = sample
        return final["sample"]

    def p_sample_loop_progressive(
        self,
        model,
        shape,
        noise=None,
        clip_denoised=True,
        denoised_fn=None,
        cond_fn=None,
        model_kwargs=None,
        device=None,
        progress=False,
    ):
        """
        Generate samples from the model and yield intermediate samples from
        each timestep of diffusion.

        Arguments are the same as p_sample_loop().
        Returns a generator over dicts, where each dict is the return value of
        p_sample().
        """
        if device is None:
            device = next(model.parameters()).device
        assert isinstance(shape, (tuple, list))
        if noise is not None:
            img = noise
        else:
            img = th.randn(*shape, device=device)
        indices = list(range(self.num_timesteps))[::-1]

        if progress:
            # Lazy import so that we don't depend on tqdm.
            from tqdm.auto import tqdm

            indices = tqdm(indices)
        self.original_grad_gen_mag = None
        self.original_grad_div_mag =None
        for i in indices:
            t = th.tensor([i] * shape[0], device=device)
            with th.no_grad():
                out = self.p_sample(
                    model,
                    img,
                    t,
                    clip_denoised=clip_denoised,
                    denoised_fn=denoised_fn,
                    cond_fn=cond_fn,
                    model_kwargs=model_kwargs,
                )
                yield out
                img = out["sample"]

    def grad_norm(self, grad_gen, grad_div):
        grad_shape = grad_gen.shape
        grad_gen_mag, grad_gen_vector = self.get_norm_flatten(grad_gen)
        grad_div_mag, grad_div_vector = self.get_norm_flatten(grad_div)

        if torch.any(grad_gen_mag == 0.0):
            print("______________________________")
            print(grad_gen_mag)
            print(grad_gen)
            print("return gen infinity")
            print("_________________________________")
            return grad_gen, grad_div
        if torch.any(grad_div_mag == 0.0):
            return grad_gen, grad_div

        rate_converge_gen = grad_gen_mag/self.original_grad_gen_mag
        rate_converge_div = grad_div_mag/self.original_grad_div_mag

        alpha_gen = rate_converge_gen/(rate_converge_gen + rate_converge_div)
        alpha_div = rate_converge_div/(rate_converge_gen + rate_converge_div)

        ceta = alpha_gen * grad_gen_mag + alpha_div * grad_div_mag

        ceta_gen = torch.unsqueeze(ceta/grad_gen_mag, dim=1)
        ceta_div = torch.unsqueeze(ceta/grad_div_mag, dim=1)
        print("_________________________________")
        print(ceta_gen)
        print(grad_gen_vector[0])
        print(ceta_div)
        print(grad_div_vector[0])
        print("_________________________________")

        new_grad_gen = (grad_gen_vector * ceta_gen).view(grad_shape)
        new_grad_div = (grad_div_vector * ceta_div).view(grad_shape)

        return new_grad_gen, new_grad_div

def _extract_into_tensor(arr, timesteps, broadcast_shape):
    """
    Extract values from a 1-D numpy array for a batch of indices.

    :param arr: the 1-D numpy array.
    :param timesteps: a tensor of indices into the array to extract.
    :param broadcast_shape: a larger shape of K dimensions with the batch
                            dimension equal to the length of timesteps.
    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.
    """
    res = th.from_numpy(arr).to(device=timesteps.device)[timesteps].float()
    while len(res.shape) < len(broadcast_shape):
        res = res[..., None]
    return res.expand(broadcast_shape)
